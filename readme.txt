Project Documentation:

Overview:
This project is designed to extract, transform, and load data from a MongoDB database into Amazon S3. 
It focuses on collecting data from multiple MongoDB collections, transforming it into a desired format, and then uploading the transformed data to an S3 bucket.

Project Structure:

project-root/
│
├── node_modules/         # Automatically generated by npm for dependencies
│
├── main.js    # This script connects to the database and extracts the data from diffrent collection as per the query, transforms the data and generates a file "transformed_data.json" for further processes.
├── s3_uploader.js        # This script uploads the generated file "transformed_data.json" to the specified s3 bucket using aws-sdk. 
│
├── package.json          # Configuration file for npm (defines dependencies and scripts)
├── package-lock.json     # Generated by npm to keep track of installed packages
├── transformed_data.json # Transformed data file (generated by the script "main.js")
└── README.md             # Project documentation

Prerequisites : 

Before running the project, ensure you have the following prerequisites:

1. Node.js and npm installed on your machine.

2. MongoDB database with relevant collections (User, Mood, Activity, Sleep) and data.

3. AWS account with an S3 bucket created.

Setup:

1. Clone the project repository to your local machine.

2. Install project dependencies by running the following command:

-> npm install

3. Configure AWS credentials:

    i. Create an IAM user in your AWS account.

    ii. Obtain the access key ID and secret access key for the IAM user.

    iii. Set up your AWS credentials in the s3_uploader.js file as follows:


        accessKeyId: 'your_access_key',
        secretAccessKey: 'your_secret_key',
        region: 'your_s3_region',

4. Modify the MongoDB connection details and target date in the main.js script:

    Replace <mongo_uri> with your MongoDB connection string.
    Replace <your_database_name> with your MongoDB database name.
    Set targetDate to the date for which you want to extract data.

Running the ETL Process: 

Execute the following command to run the data extract and transform process:

-> node src/main.js

The script will perform the following steps:

1. Connect to MongoDB.

2. Extract data from the User, Mood, Activity, and Sleep collections for users active on the specified date.

3. Transform the extracted data to the desired format, including data from Mood, Activity, and Sleep.

4. Save the transformed data locally in transformed_data.json.

Execute the following command to run the script to upload the data to the S3:

-> node src/s3_uploader.js

The script will upload the "transformed_data.json" to the mention AWS account and S3 bucket.

Data Visualization and Analysis:

We can use a visualization tool of our choice (e.g., Tableau, Power BI, or a custom web-based dashboard) to connect to the data stored in Amazon S3 and perform the desired analysis.

Calculating Perceived Energy Score:

To calculate the Perceived Energy score, we can define a formula or algorithm based on the aggregated data from Mood, Activity, and Sleep. For example, we can assign weights to different factors and calculate an overall score.

Results:
The transformed data is saved in both JSON format (transformed_data.json) in our local and uploaded to our Amazon S3 bucket. 
We can access and analyze the data from S3 as needed.